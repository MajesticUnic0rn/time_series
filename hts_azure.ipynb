{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf952d-4955-4318-b6fa-b3cc5011aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore\n",
    "import pandas as pd\n",
    "from azureml.contrib.automl.pipeline.steps import AutoMLPipelineBuilder\n",
    "from azureml.pipeline.core import Pipeline\n",
    "# Set up your workspace\n",
    "ws = Workspace.from_config()\n",
    "ws.get_details()\n",
    "\n",
    "# Set up your datastores\n",
    "dstore = ws.get_default_datastore()\n",
    "\n",
    "output = {}\n",
    "output[\"SDK version\"] = azureml.core.VERSION\n",
    "output[\"Subscription ID\"] = ws.subscription_id\n",
    "output[\"Workspace\"] = ws.name\n",
    "output[\"Resource Group\"] = ws.resource_group\n",
    "output[\"Location\"] = ws.location\n",
    "output[\"Default datastore name\"] = dstore.name\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "outputDf = pd.DataFrame(data=output, index=[\"\"])\n",
    "outputDf.T\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# setup azure workspace for heireacheal forecasting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86999193-e74f-4183-8af6-3c6d7615b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment = Experiment(ws, \"automl-hts-OnRent\")\n",
    "\n",
    "print(\"Experiment name: \" + experiment.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034ff6d-5a38-40fb-bf8d-8a6c0538361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_path = \"hts-sample-OnRent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767530d-7f8f-492e-8eed-5f0b1b8daac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = ws.get_default_datastore()\n",
    "datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bafd49b-bd93-4b84-8215-ff1a48965c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_column ='EffectiveDate'\n",
    "file_location = 'FleetForecasting_Top100ProductSubCategory_WithIHSData_Weather_BYDay_V2.csv'\n",
    "input_data_raw=pd.read_csv(file_location ,sep ='|',parse_dates=[date_column])\n",
    "input_data_copy = input_data_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011858ea-006d-4b26-bd3f-0a94044f738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.Region.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55202ca3-f44d-4458-bebf-9ce4b189a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.RegionName.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c0379-3325-4aed-9178-03970905b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.RegionName.value_counts().plot(kind='bar') \n",
    "## number of observations per region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92fdb0-56a6-4947-be54-c6fd19dcd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.sort_values(by=['EffectiveDate'], ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a1d05-f1b8-4bbb-9b4e-90ecb3df5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy['RegionName'] = input_data_copy['RegionName'].str.replace(r\"[\\\"\\',< ]\", '')\n",
    "input_data_copy['ProductCategory_Desc'] = input_data_copy['ProductCategory_Desc'].str.replace(r\"[\\\"\\',< ]\", '')\n",
    "cols = ['ProductCategory_Nbl', 'ProductCategory_Desc']\n",
    "input_data_copy['eq_nm'] = input_data_copy[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fcd077-a8de-4572-b2d6-ea54002f9411",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fd39c8-fefd-4fe3-950e-7a5b0f6af858",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_region = ['REGION04','REGION06','REGION07','REGION09','REGION08','REGION12','REGION03','REGION05','REGION14','REGION02','REGION11']\n",
    "input_data_copy = input_data_copy[input_data_copy.RegionName.isin(use_region)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bc589-9870-4b44-814d-ba54818fda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a79f3-5835-4f2e-a783-42fecb3350e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = [col for col in input_data_copy.columns if col not in ['Region','DRKey','clean_time','Rental', 'QtyOwned', \"ProductCategory_Nbl\",\"ProductCategory_Desc\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283ae6e1-d914-4166-8a49-9dd6d5d9151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_district_elect=input_data_copy.copy()\n",
    "sg_district_elect_train=sg_district_elect[feature_importance]\n",
    "sg_district_elect_train.drop(sg_district_elect_train.loc[sg_district_elect_train[date_column] < '2015-05-01 00:00:00'].index, inplace=True) # prob dont need because data is from 2016\n",
    "sg_district_elect_train.drop(sg_district_elect_train.loc[sg_district_elect_train[date_column] > '2020-05-01 01:00:00'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3425cc-0a94-4f75-a177-2ff1ec9ff806",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_district_elect_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc9191-c356-4843-8c7e-ad18a370d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_training=sg_district_elect_train\n",
    "split_date = '2019-5-20'\n",
    "train = sg_district_elect_train.loc[sg_district_elect_train[date_column] <= split_date]\n",
    "test = sg_district_elect_train.loc[sg_district_elect_train[date_column] > split_date]\n",
    "print(f\"{len(train)} days of training data \\n {len(test)} days of testing data \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634415ed-afa9-4866-b2b9-f15ddead5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da785a-f56e-4607-be08-f263918dc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[date_column].min(), train[date_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0fcf0-34e7-4010-b9a1-0cddd14c0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[date_column].min(), test[date_column].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a1649-c500-4649-b574-812461830f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "datastore = ws.get_default_datastore()\n",
    "train_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    train, target=(datastore, \"dataset/\"), name=\"OnRent_train\"\n",
    ")\n",
    "test_dataset = TabularDatasetFactory.register_pandas_dataframe(\n",
    "    test, target=(datastore, \"dataset/\"), name=\"OnRent_test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c266f3c-0d07-4b67-ba36-8330fc85f9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d0e2a4-5484-4f42-89d8-0b537ed445fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime._hts.hts_parameters import HTSTrainParameters\n",
    "\n",
    "model_explainability = True\n",
    "\n",
    "engineered_explanations = False\n",
    "# Define your hierarchy. Adjust the settings below based on your dataset.\n",
    "hierarchy = [\"RegionName\", \"Division\", \"eq_nm\"]\n",
    "training_level = \"eq_nm\"\n",
    "\n",
    "# Set your forecast parameters. Adjust the settings below based on your dataset.\n",
    "time_column_name = \"EffectiveDate\"\n",
    "label_column_name = \"OnRent\"\n",
    "forecast_horizon = 120\n",
    "\n",
    "\n",
    "automl_settings = {\n",
    "    \"task\": \"forecasting\",\n",
    "    \"primary_metric\": \"normalized_root_mean_squared_error\",\n",
    "    \"label_column_name\": label_column_name,\n",
    "    \"time_column_name\": time_column_name,\n",
    "    \"forecast_horizon\": forecast_horizon,\n",
    "    \"hierarchy_column_names\": hierarchy,\n",
    "    \"hierarchy_training_level\": training_level,\n",
    "    \"track_child_runs\": False,\n",
    "    \"pipeline_fetch_max_batch_size\": 15,\n",
    "    \"model_explainability\": model_explainability,\n",
    "    # The following settings are specific to this sample and should be adjusted according to your own needs.\n",
    "    \"iteration_timeout_minutes\": 15,\n",
    "    \"iterations\": 10,\n",
    "    \"n_cross_validations\": 2,\n",
    "}\n",
    "\n",
    "hts_parameters = HTSTrainParameters(\n",
    "    automl_settings=automl_settings,\n",
    "    hierarchy_column_names=hierarchy,\n",
    "    training_level=training_level,\n",
    "    enable_engineered_explanations=engineered_explanations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ddb289-382e-4a12-8835-262d71ed2e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Compute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98eb2d9-0643-482c-9ec7-3c8162746d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "\n",
    "# Name your cluster\n",
    "compute_name = \"hts-compute\"\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print(\"Found compute target: \" + compute_name)\n",
    "else:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size=\"Standard_D32_v3\", max_nodes=300\n",
    "    )\n",
    "    # Create the compute target\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout.\n",
    "    # If no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(\n",
    "        show_output=True, min_node_count=None, timeout_in_minutes=20\n",
    "    )\n",
    "\n",
    "    # For a more detailed view of current cluster status, use the 'status' property\n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1289cf95-29d4-4388-8aa5-aa3513112ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_pipeline_steps = AutoMLPipelineBuilder.get_many_models_train_steps(\n",
    "    experiment=experiment,\n",
    "    train_data=train_dataset,\n",
    "    compute_target=compute_target,\n",
    "    node_count=8,\n",
    "    process_count_per_node=10,\n",
    "    train_pipeline_parameters=hts_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abf307-1674-45e6-b153-2b91acb92b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "training_pipeline = Pipeline(ws, steps=training_pipeline_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7af778-2888-43e0-9ba8-5bc9f6988156",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_run = experiment.submit(training_pipeline)\n",
    "training_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430026d3-2053-4645-b4bc-b13ace59c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_explainability:\n",
    "    expl_output = training_run.get_pipeline_output(\"explanations\")\n",
    "    expl_output.download(\"training_explanations\")\n",
    "else:\n",
    "    print(\n",
    "        \"Model explanations are available only if model_explainability is set to True.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423807f-34fb-4a26-9c6a-165023e0205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if model_explainability:\n",
    "    explanations_dirrectory = os.listdir(\n",
    "        os.path.join(\"training_explanations\", \"azureml\")\n",
    "    )\n",
    "    if len(explanations_dirrectory) > 1:\n",
    "        print(\n",
    "            \"Warning! The directory contains multiple explanations, only the first one will be displayed.\"\n",
    "        )\n",
    "    print(\"The explanations are located at {}.\".format(explanations_dirrectory[0]))\n",
    "    # Now we will list all the explanations.\n",
    "    explanation_path = os.path.join(\n",
    "        \"training_explanations\",\n",
    "        \"azureml\",\n",
    "        explanations_dirrectory[0],\n",
    "        \"training_explanations\",\n",
    "    )\n",
    "    print(\"Available explanations\")\n",
    "    print(\"==============================\")\n",
    "    print(\"\\n\".join(os.listdir(explanation_path)))\n",
    "else:\n",
    "    print(\n",
    "        \"Model explanations are available only if model_explainability is set to True.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4920722-e063-452f-8cf4-1e70fd2456c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "explanation_type = \"raw\"\n",
    "level = \"Division\"\n",
    "\n",
    "if model_explainability:\n",
    "    display(\n",
    "        pd.read_csv(\n",
    "            os.path.join(explanation_path, \"{}_explanations_{}.csv\").format(\n",
    "                explanation_type, level\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8db089f-12a6-4cf0-bd77-835525177d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.runtime._hts.hts_parameters import HTSInferenceParameters\n",
    "\n",
    "inference_parameters = HTSInferenceParameters(\n",
    "    hierarchy_forecast_level=\"eq_nm\", # set to division later to find demand onwards # The setting is specific to this dataset and should be changed based on your dataset.\n",
    "    allocation_method=\"bottom_up\",\n",
    ")\n",
    "\n",
    "steps = AutoMLPipelineBuilder.get_many_models_batch_inference_steps(\n",
    "    experiment=experiment,\n",
    "    inference_data=test_dataset,\n",
    "    compute_target=compute_target,\n",
    "    inference_pipeline_parameters=inference_parameters,\n",
    "    node_count=10,\n",
    "    process_count_per_node=5,\n",
    ")\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "inference_pipeline = Pipeline(ws, steps=steps)\n",
    "inference_run = experiment.submit(inference_pipeline)\n",
    "inference_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c5ce6-d110-4906-9112-925861fe42e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = inference_run.get_pipeline_output(\"forecasts\")\n",
    "forecasts.download(\"forecast_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5589f3d-c1fb-4804-bb87-51fdb1836f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_run = experiment.submit(\n",
    "    inference_pipeline, pipeline_parameters={\"hierarchy_forecast_level\": \"eq_nm\"}\n",
    ")\n",
    "inference_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f8b9a-2ea7-44dc-8e36-9db8b8c3f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this last for this stuff\n",
    "forecasts = inference_run.get_pipeline_output(\"forecasts\")\n",
    "forecasts.download(\"forecast_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ed7f2-6db0-4ee0-81d8-7c76c19d618d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
